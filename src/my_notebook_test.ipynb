{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:29:19.503462Z",
     "start_time": "2021-10-14T09:29:19.289944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:42.920017Z",
     "start_time": "2021-10-14T09:30:38.671873Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"Loading/\")\n",
    "sys.path.insert(0,\"Preprocessing/\")\n",
    "sys.path.insert(0,\"Modeling/\")\n",
    "sys.path.insert(0,\"Evaluation/\")\n",
    "sys.path.insert(0,\"Interpretability/\")\n",
    "sys.path.insert(0,\"Monitoring/\")\n",
    "sys.path.insert(0,\"Utils/\")\n",
    "\n",
    "\n",
    "import loading\n",
    "import preprocessing\n",
    "import modeling\n",
    "import evaluation\n",
    "import interpretability\n",
    "import monitoring \n",
    "import utils as u\n",
    "\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Package allowing to reload a package (or a script), without having to reload the whole notebook\n",
    "#import importlib #no use if the magic commands in the first cell are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:42.950997Z",
     "start_time": "2021-10-14T09:30:42.922077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we find the parameters needed for the run. You have to launch this cell only if you do not launch the main script.\n",
    "\n",
    "path_conf =\"../params/conf/conf.json\"\n",
    "\n",
    "# path_conf ='../conf/conf.json'\n",
    "conf = json.load(open(path_conf, 'r'))\n",
    "\n",
    "path_log = conf['path_log'] # \"../log/my_log_file.txt\"\n",
    "log_level = conf['log_level'] # \"DEBUG\"\n",
    "\n",
    "# Be careful to launch the logger only once, otherwise each lines will be duplicated\n",
    "logger = u.my_get_logger(path_log, log_level, my_name=\"main_logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:42.996838Z",
     "start_time": "2021-10-14T09:30:42.970907Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reload of the conf file (useful when you do modifications)\n",
    "conf = json.load(open(path_conf, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:43.123488Z",
     "start_time": "2021-10-14T09:30:43.010798Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading of the dataset selected in the conf file\n",
    "df = loading.read_csv_from_name(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'Year_Birth', 'Education', 'Marital_Status',\n",
       "       ' Income ', 'Kidhome', 'Teenhome', 'Dt_Customer', 'Recency', 'MntWines',\n",
       "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
       "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
       "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
       "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
       "       'AcceptedCmp2', 'Response', 'Complain', 'Country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:44.393417Z",
     "start_time": "2021-10-14T09:30:43.131465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing of the selected dataset\n",
    "df_preprocessed, X_columns, y_column = preprocessing.main_preprocessing_from_name(df,conf)\n",
    "\n",
    "#Writting of the preprocessed dataset\n",
    "loading.write_preprocessed_csv_from_name(df_preprocessed,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:44.471081Z",
     "start_time": "2021-10-14T09:30:44.406383Z"
    }
   },
   "outputs": [],
   "source": [
    "#Basic Splitting between train and test\n",
    "X_train, X_test, y_train, y_test = preprocessing.basic_split( df_preprocessed , 0.25 , X_columns, y_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:31:00.962654Z",
     "start_time": "2021-10-14T09:30:44.483053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    5.8s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modelisation using the model selected in the conf file\n",
    "clf, best_params = modeling.main_modeling_from_name(X_train,y_train,conf)\n",
    "\n",
    "#Saving the model\n",
    "u.save_model(clf, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:24:53.588266Z",
     "start_time": "2021-10-14T09:24:53.439302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Outputs/Models/marketing_random_forest.sav\n"
     ]
    }
   ],
   "source": [
    "#Independent step from the other, we reload what we need:\n",
    "\n",
    "#Loading of the model\n",
    "clf = u.load_model(conf)\n",
    "#Loading of the preprocessed dataset\n",
    "df = loading.load_preprocessed_csv_from_name(conf)\n",
    "\n",
    "#Basic Splitting:\n",
    "y_column = u.get_y_column_from_conf(conf)\n",
    "X_columns = [x for x in df.columns if x != y_column ]\n",
    "X_train, X_test, y_train, y_test = preprocessing.basic_split( df , 0.25 , X_columns, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:24:54.058645Z",
     "start_time": "2021-10-14T09:24:53.599234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_score': 0.41379310344827586,\n",
       " 'accuracy': 0.875,\n",
       " 'recall': 0.32432432432432434,\n",
       " 'precision': 0.5714285714285714,\n",
       " 'confusion_matrix': {'tn': 226, 'fp': 9, 'fn': 25, 'tp': 12}}"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing metrics\n",
    "dict_metrics = evaluation.main_evaluation(clf, X_test, y_test, conf)\n",
    "dict_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:42.950997Z",
     "start_time": "2021-10-14T09:30:42.922077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we find the parameters needed for the run. You have to launch this cell only if you do not launch the main script.\n",
    "\n",
    "path_conf =\"../params/conf/conf_2.json\"\n",
    "conf = json.load(open(path_conf, 'r'))\n",
    "\n",
    "path_log = conf['path_log'] # \"../log/my_log_file.txt\"\n",
    "log_level = conf['log_level'] # \"DEBUG\"\n",
    "\n",
    "# Be careful to launch the logger only once, otherwise each lines will be duplicated\n",
    "logger = u.my_get_logger(path_log, log_level, my_name=\"main_logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:42.996838Z",
     "start_time": "2021-10-14T09:30:42.970907Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reload of the conf file (useful when you do modifications)\n",
    "conf = json.load(open(path_conf, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Inputs/marketing_data_2.csv'"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conf[\"paths\"][\"Inputs_path\"]+ conf[\"dict_info_files\"][conf['selected_dataset']][\"path_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:43.123488Z",
     "start_time": "2021-10-14T09:30:43.010798Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading of the dataset selected in the conf file\n",
    "df2 = loading.read_csv_from_name(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:30:44.393417Z",
     "start_time": "2021-10-14T09:30:43.131465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing of the selected dataset\n",
    "df2_preprocessed, X_columns, y_column = preprocessing.main_preprocessing_from_name(df2,conf)\n",
    "\n",
    "#Writting of the preprocessed dataset\n",
    "loading.write_preprocessed_csv_from_name(df2_preprocessed,conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:24:53.588266Z",
     "start_time": "2021-10-14T09:24:53.439302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Outputs/Models/marketing_random_forest.sav\n"
     ]
    }
   ],
   "source": [
    "#Independent step from the other, we reload what we need:\n",
    "\n",
    "#Loading of the model\n",
    "clf = u.load_model(conf,name=\"marketing_random_forest\")\n",
    "#Loading of the preprocessed dataset\n",
    "df2 = loading.load_preprocessed_csv_from_name(conf)\n",
    "\n",
    "#Basic Splitting:\n",
    "y_column = u.get_y_column_from_conf(conf)\n",
    "X_columns = [x for x in df.columns if x != y_column ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:24:54.058645Z",
     "start_time": "2021-10-14T09:24:53.599234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.4222222222222222, 'accuracy': 0.8200692041522492, 'recall': 0.2878787878787879, 'precision': 0.7916666666666666, 'confusion_matrix': {'tn': 218, 'fp': 5, 'fn': 47, 'tp': 19}}\n",
      "{'f1_score': 0.23728813559322037, 'accuracy': 0.84375, 'recall': 0.1590909090909091, 'precision': 0.4666666666666667, 'confusion_matrix': {'tn': 236, 'fp': 8, 'fn': 37, 'tp': 7}}\n",
      "{'f1_score': 0.38095238095238093, 'accuracy': 0.9097222222222222, 'recall': 0.25, 'precision': 0.8, 'confusion_matrix': {'tn': 254, 'fp': 2, 'fn': 24, 'tp': 8}}\n",
      "{'f1_score': 0.29411764705882354, 'accuracy': 0.9166666666666666, 'recall': 0.22727272727272727, 'precision': 0.4166666666666667, 'confusion_matrix': {'tn': 259, 'fp': 7, 'fn': 17, 'tp': 5}}\n"
     ]
    }
   ],
   "source": [
    "#Computing metrics\n",
    "batches= monitoring.create_batches(df2,4)\n",
    "for batch in batches:\n",
    "    y_monitored= batch[y_column]\n",
    "    X_monitored= batch.drop(y_column,axis=1)\n",
    "    dict_metrics = evaluation.main_evaluation(clf, X_monitored, y_monitored, conf)\n",
    "    print(dict_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretabily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:54:11.594730Z",
     "start_time": "2021-10-12T15:54:11.215912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1\n",
      "\t ->kolmogorov_smirnov:\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -Response\n",
      "\t \t -Complain\n",
      "\t ->t_test:\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -Complain\n",
      "\t ->levene_test:\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -NumStorePurchases\n",
      "\t \t -Complain\n",
      "**************************************** \n",
      "\n",
      "batch 2\n",
      "\t ->kolmogorov_smirnov:\n",
      "\t \t -Response\n",
      "\t \t -Complain\n",
      "\t ->t_test:\n",
      "\t \t -Response\n",
      "\t \t -Complain\n",
      "\t ->levene_test:\n",
      "\t \t -Teenhome\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -Response\n",
      "\t \t -Complain\n",
      "**************************************** \n",
      "\n",
      "batch 3\n",
      "\t ->kolmogorov_smirnov:\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -Response\n",
      "\t \t -Complain\n",
      "\t ->t_test:\n",
      "\t \t -Complain\n",
      "\t ->levene_test:\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -NumStorePurchases\n",
      "\t \t -Response\n",
      "\t \t -Complain\n",
      "**************************************** \n",
      "\n",
      "batch 4\n",
      "\t ->kolmogorov_smirnov:\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -Response\n",
      "\t \t -Complain\n",
      "\t ->t_test:\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -Complain\n",
      "\t ->levene_test:\n",
      "\t \t -Income\n",
      "\t \t -NumDealsPurchases\n",
      "\t \t -NumStorePurchases\n",
      "\t \t -Complain\n",
      "**************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch= batches[0]\n",
    "monitoring.main_monitoring(df,batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
